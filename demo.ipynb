{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES\n",
    "lemmatizer = Lemmatizer(LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES)\n",
    "\n",
    "import neuralcoref\n",
    "nlp.add_pipe(neuralcoref.NeuralCoref(nlp.vocab,blacklist=False),name=\"neuralcoref\")\n",
    "\n",
    "from main2 import ConnoFramer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_path = '/Users/maria/Documents/data/FramesAgencyPower/agency_power.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "# Small demo (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_stories = [\"I was just thinking about walking down the street, when my shoelace snapped. I had to call my doctor to pick me up. I felt so bad I also called my friend Katie, who came in her car. She was a lifesaver. My friend Jack is nice.\",\n",
    "                   \"My doctor fixed my shoe. I thanked him. Then Susan arrived. Now she is calling the doctor too.\"]\n",
    "text_ids = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-06 10:19:36 Complete!\n"
     ]
    }
   ],
   "source": [
    "framer = ConnoFramer()\n",
    "framer.train(lexicon_path, \n",
    "             example_stories,\n",
    "             text_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function main2.ConnoFramer.__score_dataset.<locals>.<lambda>()>,\n",
       "            {'i': defaultdict(int, {'positive': 1, 'negative': 2}),\n",
       "             'my doctor': defaultdict(int, {'positive': 4, 'negative': 0}),\n",
       "             'susan': defaultdict(int, {'positive': 0, 'negative': 1})})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "framer.get_score_totals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function main2.ConnoFramer.__score_document.<locals>.<lambda>()>,\n",
       "            {'my doctor': defaultdict(int, {'positive': 3, 'negative': 0}),\n",
       "             'susan': defaultdict(int, {'negative': 1, 'positive': 0})})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "framer.get_scores_for_doc(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {('my doctor', 'fix'): 1,\n",
       "             ('susan', 'arrive'): 1,\n",
       "             ('susan', 'call'): 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "framer.count_nsubj_for_doc(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {('my doctor', 'thank'): 1, ('my doctor', 'call'): 1})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "framer.count_dobj_for_doc(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function main2.ConnoFramer.__score_document.<locals>.<lambda>()>,\n",
       "            {'i': defaultdict(int, {'positive': 1, 'negative': 2}),\n",
       "             'my doctor': defaultdict(int, {'positive': 1, 'negative': 0})})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "framer.get_scores_for_doc(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {('i', 'think'): 1,\n",
       "             ('i', 'have'): 1,\n",
       "             ('i', 'feel'): 1,\n",
       "             ('i', 'call'): 1})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "framer.count_nsubj_for_doc(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {('i', 'pick'): 1, ('my doctor', 'call'): 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "framer.count_dobj_for_doc(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "# Bigger demo (new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = []\n",
    "text_ids = []\n",
    "stories_path = '/Users/maria/Documents/data/narrativity/litbank/original'   # Litbank corpus here: https://github.com/dbamman/litbank\n",
    "\n",
    "j = 0\n",
    "for _file_name in os.listdir(stories_path):\n",
    "    _lines = []\n",
    "    for _line in open(stories_path + '/' + _file_name, 'r'):\n",
    "        \n",
    "        if _line.strip():\n",
    "            _lines.append(_line.strip())\n",
    "\n",
    "    # Randomly sample 100 paragraphs from each book\n",
    "    for _line in random.sample(_lines, 100):        \n",
    "        texts.append(_line)\n",
    "        text_ids.append(j)\n",
    "        j += 1\n",
    "\n",
    "len(texts), len(text_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "framer = ConnoFramer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-06 10:35:13 Processed 0 out of 10000\n",
      "2023-02-06 10:35:15 Processed 100 out of 10000\n",
      "2023-02-06 10:35:16 Processed 200 out of 10000\n",
      "2023-02-06 10:35:17 Processed 300 out of 10000\n",
      "2023-02-06 10:35:18 Processed 400 out of 10000\n",
      "2023-02-06 10:35:19 Processed 500 out of 10000\n",
      "2023-02-06 10:35:20 Processed 600 out of 10000\n",
      "2023-02-06 10:35:21 Processed 700 out of 10000\n",
      "2023-02-06 10:35:22 Processed 800 out of 10000\n",
      "2023-02-06 10:35:23 Processed 900 out of 10000\n",
      "2023-02-06 10:35:24 Processed 1000 out of 10000\n",
      "2023-02-06 10:35:25 Processed 1100 out of 10000\n",
      "2023-02-06 10:35:26 Processed 1200 out of 10000\n",
      "2023-02-06 10:35:27 Processed 1300 out of 10000\n",
      "2023-02-06 10:35:28 Processed 1400 out of 10000\n",
      "2023-02-06 10:35:29 Processed 1500 out of 10000\n",
      "2023-02-06 10:35:29 Processed 1600 out of 10000\n",
      "2023-02-06 10:35:30 Processed 1700 out of 10000\n",
      "2023-02-06 10:35:31 Processed 1800 out of 10000\n",
      "2023-02-06 10:35:32 Processed 1900 out of 10000\n",
      "2023-02-06 10:35:33 Processed 2000 out of 10000\n",
      "2023-02-06 10:35:34 Processed 2100 out of 10000\n",
      "2023-02-06 10:35:35 Processed 2200 out of 10000\n",
      "2023-02-06 10:35:36 Processed 2300 out of 10000\n",
      "2023-02-06 10:35:37 Processed 2400 out of 10000\n",
      "2023-02-06 10:35:38 Processed 2500 out of 10000\n",
      "2023-02-06 10:35:39 Processed 2600 out of 10000\n",
      "2023-02-06 10:35:40 Processed 2700 out of 10000\n",
      "2023-02-06 10:35:41 Processed 2800 out of 10000\n",
      "2023-02-06 10:35:42 Processed 2900 out of 10000\n",
      "2023-02-06 10:35:43 Processed 3000 out of 10000\n",
      "2023-02-06 10:35:44 Processed 3100 out of 10000\n",
      "2023-02-06 10:35:45 Processed 3200 out of 10000\n",
      "2023-02-06 10:35:46 Processed 3300 out of 10000\n",
      "2023-02-06 10:35:47 Processed 3400 out of 10000\n",
      "2023-02-06 10:35:48 Processed 3500 out of 10000\n",
      "2023-02-06 10:35:49 Processed 3600 out of 10000\n",
      "2023-02-06 10:35:50 Processed 3700 out of 10000\n",
      "2023-02-06 10:35:51 Processed 3800 out of 10000\n",
      "2023-02-06 10:35:52 Processed 3900 out of 10000\n",
      "2023-02-06 10:35:53 Processed 4000 out of 10000\n",
      "2023-02-06 10:35:54 Processed 4100 out of 10000\n",
      "2023-02-06 10:35:55 Processed 4200 out of 10000\n",
      "2023-02-06 10:35:56 Processed 4300 out of 10000\n",
      "2023-02-06 10:35:57 Processed 4400 out of 10000\n",
      "2023-02-06 10:35:58 Processed 4500 out of 10000\n",
      "2023-02-06 10:35:59 Processed 4600 out of 10000\n",
      "2023-02-06 10:36:00 Processed 4700 out of 10000\n",
      "2023-02-06 10:36:01 Processed 4800 out of 10000\n",
      "2023-02-06 10:36:02 Processed 4900 out of 10000\n",
      "2023-02-06 10:36:03 Processed 5000 out of 10000\n",
      "2023-02-06 10:36:04 Processed 5100 out of 10000\n",
      "2023-02-06 10:36:05 Processed 5200 out of 10000\n",
      "2023-02-06 10:36:06 Processed 5300 out of 10000\n",
      "2023-02-06 10:36:07 Processed 5400 out of 10000\n",
      "2023-02-06 10:36:08 Processed 5500 out of 10000\n",
      "2023-02-06 10:36:09 Processed 5600 out of 10000\n",
      "2023-02-06 10:36:10 Processed 5700 out of 10000\n",
      "2023-02-06 10:36:11 Processed 5800 out of 10000\n",
      "2023-02-06 10:36:12 Processed 5900 out of 10000\n",
      "2023-02-06 10:36:13 Processed 6000 out of 10000\n",
      "2023-02-06 10:36:14 Processed 6100 out of 10000\n",
      "2023-02-06 10:36:15 Processed 6200 out of 10000\n",
      "2023-02-06 10:36:16 Processed 6300 out of 10000\n",
      "2023-02-06 10:36:17 Processed 6400 out of 10000\n",
      "2023-02-06 10:36:18 Processed 6500 out of 10000\n",
      "2023-02-06 10:36:19 Processed 6600 out of 10000\n",
      "2023-02-06 10:36:20 Processed 6700 out of 10000\n",
      "2023-02-06 10:36:21 Processed 6800 out of 10000\n",
      "2023-02-06 10:36:22 Processed 6900 out of 10000\n",
      "2023-02-06 10:36:23 Processed 7000 out of 10000\n",
      "2023-02-06 10:36:24 Processed 7100 out of 10000\n",
      "2023-02-06 10:36:25 Processed 7200 out of 10000\n",
      "2023-02-06 10:36:26 Processed 7300 out of 10000\n",
      "2023-02-06 10:36:27 Processed 7400 out of 10000\n",
      "2023-02-06 10:36:28 Processed 7500 out of 10000\n",
      "2023-02-06 10:36:29 Processed 7600 out of 10000\n",
      "2023-02-06 10:36:30 Processed 7700 out of 10000\n",
      "2023-02-06 10:36:31 Processed 7800 out of 10000\n",
      "2023-02-06 10:36:32 Processed 7900 out of 10000\n",
      "2023-02-06 10:36:33 Processed 8000 out of 10000\n",
      "2023-02-06 10:36:34 Processed 8100 out of 10000\n",
      "2023-02-06 10:36:35 Processed 8200 out of 10000\n",
      "2023-02-06 10:36:36 Processed 8300 out of 10000\n",
      "2023-02-06 10:36:37 Processed 8400 out of 10000\n",
      "2023-02-06 10:36:38 Processed 8500 out of 10000\n",
      "2023-02-06 10:36:39 Processed 8600 out of 10000\n",
      "2023-02-06 10:36:40 Processed 8700 out of 10000\n",
      "2023-02-06 10:36:41 Processed 8800 out of 10000\n",
      "2023-02-06 10:36:42 Processed 8900 out of 10000\n",
      "2023-02-06 10:36:43 Processed 9000 out of 10000\n",
      "2023-02-06 10:36:44 Processed 9100 out of 10000\n",
      "2023-02-06 10:36:45 Processed 9200 out of 10000\n",
      "2023-02-06 10:36:46 Processed 9300 out of 10000\n",
      "2023-02-06 10:36:47 Processed 9400 out of 10000\n",
      "2023-02-06 10:36:49 Processed 9500 out of 10000\n",
      "2023-02-06 10:36:50 Processed 9600 out of 10000\n",
      "2023-02-06 10:36:51 Processed 9700 out of 10000\n",
      "2023-02-06 10:36:52 Processed 9800 out of 10000\n",
      "2023-02-06 10:36:53 Processed 9900 out of 10000\n",
      "2023-02-06 10:36:54 Complete!\n"
     ]
    }
   ],
   "source": [
    "framer.train(lexicon_path, texts, text_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persona_score_dict = framer.get_score_totals()\n",
    "len(persona_score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persona_sum_dict = {_persona: _category_score_dict['positive']-_category_score_dict['negative'] for _persona, _category_score_dict in persona_score_dict.items()}\n",
    "len(persona_sum_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "179 292 113\n",
      "\n",
      "you\n",
      "37 75 38\n",
      "\n",
      "mary\n",
      "11 11 0\n",
      "\n",
      "george\n",
      "6 7 1\n",
      "\n",
      "rosamond\n",
      "3 3 0\n",
      "\n",
      "jane\n",
      "3 4 1\n",
      "\n",
      "mrs. miller\n",
      "2 2 0\n",
      "\n",
      "isabella\n",
      "2 2 0\n",
      "\n",
      "deborah\n",
      "2 2 0\n",
      "\n",
      "tommy\n",
      "2 3 1\n",
      "\n",
      "sikes\n",
      "2 2 0\n",
      "\n",
      "dick\n",
      "2 5 3\n",
      "\n",
      "mr. hale\n",
      "2 2 0\n",
      "\n",
      "theobald\n",
      "2 2 0\n",
      "\n",
      "miriam\n",
      "2 2 0\n",
      "\n",
      "michael\n",
      "2 2 0\n",
      "\n",
      "freddy malins\n",
      "2 2 0\n",
      "\n",
      "jo\n",
      "2 3 1\n",
      "\n",
      "mrs. selwyn\n",
      "2 2 0\n",
      "\n",
      "joe\n",
      "2 3 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _persona, _sum in sorted(persona_sum_dict.items(), key=lambda x: x[1], reverse=True)[:20]:\n",
    "    print(_persona)\n",
    "    print(_sum, persona_score_dict[_persona]['positive'], persona_score_dict[_persona]['negative'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "connoFrameEnv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66412c03f91e9a42e9c41dd543b50b96eee08a8e3011708689019231b0abadf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
